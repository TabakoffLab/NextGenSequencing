BNLx and SHR Liver rRNA-Depleted Total RNA From UCD Genomics Core
=========================
* 6 liver ribosomal RNA depleted total RNA samples, SHR1, SHR5, SHR25, BNLx1, BNLx2, and BNLx3
* synthetic spikes included Mix 1 in SHR1, BNLx1, and BNLx2 and Mix 2 in SHR5, SHR25, and BNLx3
* 2X100 paired end reads using the stranded protocol
* received 4/1/14


1. Unzip FASTQ files on Yucca - DONE
----------------------------
```
qsub -q smp-q /home/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/unzip.yucca.sh
```

2. Determine number of reads sent for each sample - DONE
----------------------------------------------------------
```
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/countRawReads.liver.sh
```

```{r,echo=FALSE}
rm(list=ls())
options(stringsAsFactors=FALSE)
setwd("/Volumes/LauraS/NextGenSeq/BNLx.SHR.Liver.totalRNA.UCD/")
rawCounts = read.table(file="data/rawReadCounts.09Jul14.txt",sep=" ",header=FALSE,fill=TRUE)

rawCounts$readFrag = as.numeric(rawCounts$V3)
rawCounts$sample = unlist(lapply(strsplit(rawCounts$V1,split="/",fixed=TRUE),function(a) gsub("BNLX_","BNLx",gsub("SHR_.","SHR",a[length(a)]))))
rawCounts$sample = unlist(lapply(strsplit(rawCounts$sample,split="_",fixed=TRUE),function(a) a[1]))
rawCounts$sample[grep("L001",rawCounts$V1)] = paste(rawCounts$sample[grep("L001",rawCounts$V1)],"dup",sep=".")

readFragments = aggregate(rawCounts$readFrag,by=list(sample=rawCounts$sample),sum)
readFragments$numPairedReads = prettyNum(readFragments$x/2,big.mark=",",scientific=FALSE)
readFragments$numReadFragments = prettyNum(readFragments$x,big.mark=",",scientific=FALSE)

readFragments=readFragments[,colnames(readFragments)!="x"]
forPrint = readFragments[,c("sample","numPairedReads","numReadFragments")]
colnames(forPrint) = c("sample","Number of Paired-End Reads","Number of Read Fragments")
```

Raw Reads/Read Fragments
---------------------------

```{r, results='asis',echo=FALSE}
kable(forPrint,align=rep("c",ncol(readFragments)))
```

Total Number of Paired End Reads: `r prettyNum(sum(rawCounts$readFrag)/2,big.mark=",",scientific=FALSE)`  
Total Number of Read Fragments:  `r prettyNum(sum(rawCounts$readFrag),big.mark=",",scientific=FALSE)`  
Average Number of Paired End Reads Per Sample: `r prettyNum(sum(rawCounts$readFrag)/nrow(rawCounts),big.mark=",",scientific=FALSE)`  

3. Trim Reads for Adaptors and for Quality - DONE
--------------------------------------------
```
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/trimReads.yucca.sh
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/trimReads.dups.sh
```

4. Characterizing Trimmed Reads - DONE
----------------------------------
```
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/countTrimmedReads.liver.sh
```

```{r,echo=FALSE}
options(stringsAsFactors=FALSE)
setwd("/Volumes/LauraS/NextGenSeq/BNLx.SHR.Liver.totalRNA.UCD/")

trimmed = read.table(file="data/trimmedReadCounts.02Jul14.txt",sep="",header=FALSE)
trimmed$file = unlist(lapply(strsplit(trimmed$V1,split="/",fixed=TRUE),function(a) a[length(a)]))
trimmed$sample = unlist(lapply(strsplit(trimmed$V1,split="/",fixed=TRUE),function(a) gsub("BNLX_","BNLx",gsub("SHR_.","SHR",a[length(a)]))))
trimmed$sample = unlist(lapply(strsplit(trimmed$sample,split="_",fixed=TRUE),function(a) a[1]))
trimmed$read = unlist(lapply(strsplit(trimmed$file,split="_",fixed=TRUE),function(a) a[grep("L00",a)+1]))

bySample = merge(trimmed[trimmed$read=="R1",c("sample","V2","V3")],trimmed[trimmed$read=="R2",c("sample","V2")],by="sample")
bySample$numReadFrag = bySample$V3*2
colnames(bySample) = c("sample","avgFragLength.R1","numReads","avgFragLength.R2","numReadFrag")

bySample = merge(readFragments,bySample,by="sample")
bySample$pctReadsAfterTrim = paste(sprintf("%.1f",round(100*bySample$numReads/as.numeric(gsub(",","",bySample$numPairedReads)),1)),"%",sep="")

forPrint2 = bySample[,c("sample","numPairedReads","numReadFragments","avgFragLength.R1","avgFragLength.R2","numReadFrag","pctReadsAfterTrim")]
forPrint2$avgFragLength.R1 = sprintf("%.1f",round(forPrint2$avgFragLength.R1,1))
forPrint2$avgFragLength.R2 = sprintf("%.1f",round(forPrint2$avgFragLength.R2,1))
forPrint2$numReadFrag = prettyNum(forPrint2$numReadFrag,big.mark=",",scientific=FALSE)

colnames(forPrint2) = c("sample","Number of Paired-End Reads","Number of Read Fragments","Average Read Fragment Length After Trimming (first read fragment)","Average Read Fragment Length After Trimming (second read fragment)","Number of Read Fragments After Trimming","Percent of Read Fragments That Remained After Trimming")
```

Trimmed Reads/Read Fragments
---------------------------

```{r, results='asis',echo=FALSE}
kable(forPrint2,align=rep("c",ncol(forPrint2)))
```

Total Number of Paired End Reads After Trimming: `r prettyNum(sum(trimmed$V3)/2,big.mark=",",scientific=FALSE)`  
Total Number of Read Fragments After Trimming:  `r prettyNum(sum(trimmed$V3),big.mark=",",scientific=FALSE)`  
Average Number of Paired End Reads Per Sample After Trimming: `r prettyNum(mean(trimmed$V3),big.mark=",",scientific=FALSE)`  


5.  Generate Strain-Specific Genomes Including Spike-In Sequences - DONE
-------------------------------------------
```
qsub -q smp-q /home/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/createGenomeIndex.yucca.sh
```

6. Align trimmed reads to ribosomal RNA - RUNNING
-----------------------------------
```
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/alignTo.rRNA.liver.01Jul14.sh
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/alignTo.rRNA.liver.dups.10Jul14.sh
```

**move files**
```
get BNLx1.rRNA/align_summary.txt rRNA.summary.BNLx1.txt  
get BNLx2.rRNA/align_summary.txt rRNA.summary.BNLx2.txt  
get BNLx3.rRNA/align_summary.txt rRNA.summary.BNLx3.txt  
get SHR1.rRNA/align_summary.txt rRNA.summary.SHR1.txt  
get SHR25.rRNA/align_summary.txt rRNA.summary.SHR25.txt  
get SHR5.rRNA/align_summary.txt rRNA.summary.SHR5.txt  
get SHR25.dup.rRNA/align_summary.txt rRNA.summary.SHR25.dup.txt  
get BNLx3.dup.rRNA/align_summary.txt rRNA.summary.BNLx3.dup.txt  
```

```{r,echo=FALSE}
rm(list=ls())
setwd("/Volumes/LauraS/NextGenSeq/BNLx.SHR.Liver.totalRNA.UCD/data")
options(stringsAsFactors=FALSE)

sampleList = c(paste(rep(c("BNLx","SHR"),each=3),c(1:3,1,25,5),sep=""),"BNLx3.dup","SHR25.dup")

rStats = c()
for(i in sampleList){
  x = read.table(file=paste("rRNA.summary.",i,".txt",sep=""),sep="\t",header=FALSE)
  sample = i
  numReads = as.numeric(gsub(":","",gsub("Input","",x[2,1])))       
  mappedLeft = as.numeric(gsub(":","",gsub("Mapped","",unlist(lapply(strsplit(x[3,1],split="(",fixed=TRUE),function(a) a[1])))))
  mappedRight = as.numeric(gsub(":","",gsub("Mapped ","",unlist(lapply(strsplit(x[7,1],split="(",fixed=TRUE),function(a) a[1])))))
  mappedPairs = as.numeric(gsub("Aligned pairs: ","",x[10,1]))  
  rStats = rbind(rStats,data.frame(sample,numReads,mappedLeft,mappedRight,mappedPairs))
}

rStats$numReadFrag = (rStats$mappedLeft + rStats$mappedRight)
rStats$numDeletedPairedReads = (rStats$mappedLeft + rStats$mappedRight - rStats$mappedPairs)

rStats = rStats[,c("sample","numReads","numReadFrag","mappedPairs","numDeletedPairedReads")]

rTable = data.frame(sample=rStats$sample,numTrimmedReads=prettyNum(rStats$numReads,big.mark=","),numDeleted=prettyNum(rStats$numDeletedPairedReads,big.mark=","),pctRiboReads=as.numeric(rStats$numDeletedPairedReads)/as.numeric(rStats$numReads),numRemaining=prettyNum(rStats$numReads-rStats$numDeletedPairedReads,big.mark=","))

rTable$pctRiboReads = paste(sprintf("%.1f",round(100*rTable$pctRiboReads,1)),"%",sep="")
colnames(rTable) = c("Sample","Number of Paired-End Reads After Trimming","Number of Paired-End Reads with at Least One Fragment Aligned to rRNA","Percent of Paired-End Reads Aligned to rRNA","Number of Paired-End Reads NOT Aligned to rRNA")
rTable = rTable[order(rTable$Sample),]
```

```{r, results='asis',echo=FALSE}
kable(rTable,align=rep("c",ncol(alignTable)))
```

Total Number of Paired End Reads After Eliminating rRNA Aligned Reads: `r prettyNum(sum(rStats$numReads-rStats$numDeletedPairedReads),big.mark=",",scientific=FALSE)`  
Average Number of Paired End Reads Per Sample After Eliminating rRNA Aligned Reads: `r prettyNum(mean(rStats$numReads-rStats$numDeletedPairedReads),big.mark=",",scientific=FALSE)`  


7. Convert unmapped.bam into fastq files  - RUNNING (BNLx3 duplicate)
----------------------------------------
```
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/convertToFastQ.liver.sh
```

8. Alignment of Raw Reads to Strain-Specific Genomes With Mitochondrial Chromosome - waiting for BNLx3 duplicate FASTQ files
------------------------------------

```
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/tophatAlign.liver.sh
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/tophatAlign.liver.v2.sh
```

***STOPPED HERE***




9.  Sort and Merge Aligned Reads By Strain
--------------------------

```
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/sortAndMerge.liver.BNLx.sh
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/sortAndMerge.liver.SHR.sh
```











9.  Characterization of Aligned Reads
---------------------------
**move files**
```
cd /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/alignedReads
get ./BNLx1.withMT/align_summary.txt align_summary.BNLx1.txt
get ./BNLx2.withMT/align_summary.txt align_summary.BNLx2.txt
get ./BNLx3.withMT/align_summary.txt align_summary.BNLx3.txt
get ./SHR1.withMT/align_summary.txt align_summary.SHR1.txt
get ./SHR5.withMT/align_summary.txt align_summary.SHR5.txt
get ./SHR25.withMT/align_summary.txt align_summary.SHR25.txt
```

```{r,echo=FALSE,eval=FALSE}
sampleList=c("BNLx1","BNLx2","BNLx3","SHR1","SHR5","SHR25")

alignStats = c()
for(i in sampleList){
  x = read.table(file=paste("/Volumes/LauraS/NextGenSeq/BNLx.SHR.Liver.totalRNA.UCD/data/align_summary.",i,".txt",sep=""),sep="\t",header=FALSE)
  sample = i
  numReads = as.numeric(gsub(":","",gsub("Input","",x[2,1])))       
  mappedLeft = as.numeric(gsub(":","",gsub("Mapped","",unlist(lapply(strsplit(x[3,1],split="(",fixed=TRUE),function(a) a[1])))))
  mappedRight = as.numeric(gsub(":","",gsub("Mapped ","",unlist(lapply(strsplit(x[7,1],split="(",fixed=TRUE),function(a) a[1])))))
  multiLeft = as.numeric(gsub("of these: ","",unlist(lapply(strsplit(x[4,1],split="(",fixed=TRUE),function(a) a[1]))))
  multiRight = as.numeric(gsub("of these: ","",unlist(lapply(strsplit(x[8,1],split="(",fixed=TRUE),function(a) a[1]))))
  lotsLeft = as.numeric(gsub(" have >20)","",unlist(lapply(strsplit(x[4,1],split="(",fixed=TRUE),function(a) a[3]))))
  lotsRight = as.numeric(gsub(" have >20)","",unlist(lapply(strsplit(x[8,1],split="(",fixed=TRUE),function(a) a[3]))))
  mappedPairs = as.numeric(gsub("Aligned pairs: ","",x[10,1]))  
  multiPairs = as.numeric(gsub("of these: ","",unlist(lapply(strsplit(x[11,1],split="(",fixed=TRUE),function(a) a[1]))))
  discordPairs = as.numeric(gsub("and: ","",unlist(lapply(strsplit(x[12,1],split="(",fixed=TRUE),function(a) a[1]))))

  alignStats = rbind(alignStats,data.frame(sample,numReads,mappedLeft,mappedRight,multiLeft,multiRight,lotsLeft,lotsRight,mappedPairs,multiPairs,discordPairs))
}

alignTable = data.frame(t(alignStats))
colnames(alignTable) = alignTable[1,]
alignTable = alignTable[-1,]

alignTable$BNLx1.pct = as.numeric(alignTable$BNLx1)/as.numeric(alignTable["numReads","BNLx1"])
alignTable$BNLx2.pct = as.numeric(alignTable$BNLx2)/as.numeric(alignTable["numReads","BNLx2"])
alignTable$BNLx3.pct = as.numeric(alignTable$BNLx3)/as.numeric(alignTable["numReads","BNLx3"])
alignTable$SHR1.pct = as.numeric(alignTable$SHR1)/as.numeric(alignTable["numReads","SHR1"])
alignTable$SHR5.pct = as.numeric(alignTable$SHR5)/as.numeric(alignTable["numReads","SHR5"])
alignTable$SHR25.pct = as.numeric(alignTable$SHR25)/as.numeric(alignTable["numReads","SHR25"])

## format numbers
for(i in sampleList){
  alignTable[,i] = prettyNum(alignTable[,i],big.mark=",",scientific=FALSE)
  alignTable[,paste(i,".pct",sep="")] = paste(sprintf("%.2f", round(alignTable[,paste(i,".pct",sep="")]*100,2)),"%",sep="")
  }

## add labels
labels = read.table(file="/Volumes/LauraS/NextGenSeq/misc/alignLabels.txt",sep="\t",header=TRUE)
alignTable = merge(labels,alignTable,by.x="var",by.y=0)
alignTable = alignTable[order(alignTable$orderNum),]
alignTable = alignTable[,c("Label",paste(rep(sampleList,each=2),rep(c("",".pct"),length(sampleList)),sep=""))]
colnames(alignTable) = c("Label",paste(rep(sampleList,each=2),rep(c(" (num)"," (pct)"),length(sampleList)),sep=""))
```

### Statistics on Alignment to Genome
```{r, results='asis',echo=FALSE,eval=FALSE}
kable(alignTable,align=rep("c",ncol(alignTable)),row.names=FALSE)
```

10.  Examine Spike-In Expression - HAVEN'T RUN FOR DATA WITH MITO
-----------------------

```
qsub -q smp-q /home/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/quantifyControlSpikes.21Apr14.sh
```

```{r,echo=FALSE,eval=FALSE,eval=FALSE}
sampleList=c("BNLx1","BNLx2","BNLx3","SHR1","SHR5","SHR25")

spikes = read.table(file="/Volumes/LauraS/BxH.HxB.Rats/RNA-Seq/spikeSource/ERCC_Controls_Analysis.txt",sep="\t",header=TRUE)
colnames(spikes) = gsub("concentration.in.","",gsub("..attomoles.ul.","",colnames(spikes)))

spikeCnt = spikes
for(i in sampleList){
  x = read.table(file=paste("/Volumes/LauraS/BNLx.SHR/RNA-Seq.Liver/totalRNA.UCD/alignedReads/",i,"/readCounts.spikes.txt",sep=""),sep="\t",header=FALSE,fill=TRUE)
  x$ERCC.ID = unlist(lapply(strsplit(x$V1,split=" E",fixed=TRUE),function(a) paste("E",a[2],sep="")))
  x[,i] = as.numeric(unlist(lapply(strsplit(x$V1,split=" E",fixed=TRUE),function(a) a[1])))
  x = x[,c("ERCC.ID",i)]
  spikeCnt = merge(spikeCnt,x,by="ERCC.ID",all.x=TRUE)
  spikeCnt[is.na(spikeCnt[,i]),i] = 0
}

mapped = rowSums(alignStats[,c("mappedLeft","mappedRight")])
names(mapped) = alignStats$sample

pctSpike = colSums(spikeCnt[,sampleList])/mapped
pctSpike.allReads = colSums(spikeCnt[,sampleList]) / (2*alignStats$numReads)


spikeSummary = data.frame(cbind(sample=sampleList,numReads=prettyNum((2*alignStats$numReads),big.mark=",",scientific=FALSE),numAlignedReads=prettyNum(mapped,big.mark=",",scientific=FALSE),numSpikeReads=prettyNum(colSums(spikeCnt[,sampleList]),big.mark=",",scientific=FALSE),pctSpike=paste(sprintf("%.2f", round(pctSpike*100,2)),"%",sep=""),pctSpike.allReads=paste(sprintf("%.2f", round(pctSpike.allReads*100,2)),"%",sep="")))

colnames(spikeSummary) = c("Sample","Num of Read Fragments","Num of Aligned Read Fragments","Num of Read Fragments Aligned to Spikes","Percent of Aligned Read Fragments Aligned to Spikes","Percent of All Read Fragments Aligned to Spikes")
```

### Synthetic spike-in summary
```{r, results='asis',echo=FALSE,eval=FALSE}
kable(spikeSummary,align=rep("c",ncol(spikeSummary)),row.names=FALSE)
```


### Comparison of raw read count versus spike concentrations
```{r,echo=FALSE,fig.width=12, fig.height=4,eval=FALSE}
library(limma)

mix = as.factor(c(1,1,2,1,2,2))
design = model.matrix(~ -1 + mix)
counts = spikeCnt[,sampleList]

voomed.spikeSize = voom(counts,design=design,normalize.method="none",lib.size=colSums(spikeCnt[spikeCnt$log2.Mix.1.Mix.2.=="0",sampleList]))
voomed.librarySize = voom(counts,design=design,normalize.method="none",lib.size=mapped)

par(mfrow=c(1,3))
plot(log2(spikeCnt$Mix.1),log2(spikeCnt$BNLx1+1),xlab="log base 2 of spike concentration",ylab="log base 2 of read count plus 1")
points(log2(spikeCnt$Mix.1),log2(spikeCnt$SHR1+1),col="red")
points(log2(spikeCnt$Mix.1),log2(spikeCnt$BNLx2+1),col="blue")
points(log2(spikeCnt$Mix.2),log2(spikeCnt$SHR5+1),col="green")
points(log2(spikeCnt$Mix.2),log2(spikeCnt$SHR25+1),col="orange")
points(log2(spikeCnt$Mix.2),log2(spikeCnt$BNLx3+1),col="yellow")

plot(log2(spikeCnt$Mix.1),voomed.librarySize$E[,1],xlab="log base 2 of spike concentration",ylab="voomed values using all aligned reads as library size")
points(log2(spikeCnt$Mix.1),voomed.librarySize$E[,2],col="red")
points(log2(spikeCnt$Mix.2),voomed.librarySize$E[,3],col="blue")
points(log2(spikeCnt$Mix.1),voomed.librarySize$E[,4],col="green")
points(log2(spikeCnt$Mix.2),voomed.librarySize$E[,5],col="orange")
points(log2(spikeCnt$Mix.2),voomed.librarySize$E[,6],col="yellow")


plot(log2(spikeCnt$Mix.1),voomed.spikeSize$E[,1],xlab="log base 2 of spike concentration",ylab="voomed values using spike counts only for library size")
points(log2(spikeCnt$Mix.1),voomed.spikeSize$E[,2],col="red")
points(log2(spikeCnt$Mix.2),voomed.spikeSize$E[,3],col="blue")
points(log2(spikeCnt$Mix.1),voomed.spikeSize$E[,4],col="green")
points(log2(spikeCnt$Mix.2),voomed.spikeSize$E[,5],col="orange")
points(log2(spikeCnt$Mix.2),voomed.spikeSize$E[,6],col="yellow")

```
Each color represents a different sample.  The y-axis of the plot on the left represents the log base 2 of the read count for each spike plus 1. The y-axis of the plot in the middle represents the "voom" expression values when the library size is calculated as ALL mapped reads. The y-axis of the plot on the right represents the "voom" expression values when the library size is calculated as only the reads that map to a synthetic spike-in.  

### Expected Differential Expression In Spikes Between Mixes
```{r fig.width=8,fig.height=6,echo=FALSE,eval=FALSE}
par(mfrow=c(1,1))
contrast.matrix = makeContrasts(mix1 - mix2,levels=design)
fit = lmFit(voomed.spikeSize$E,design=design,weights=voomed.spikeSize$weights)
contrast.results = contrasts.fit(fit,contrasts=contrast.matrix)
eBayes.results = eBayes(contrast.results)


results = cbind(spikeCnt$ERCC.ID,eBayes.results$coefficients,eBayes.results$p.value)
colnames(results) = c("ERCC.ID","diff","pvalue")
results = merge(results,spikeCnt,by="ERCC.ID")

reduced = results[results$Mix.1>0.5 & results$Mix.2>0.5,]
boxplot(as.numeric(reduced$diff) ~ as.factor(reduced$log2.Mix.1.Mix.2.))
abline(h=-1,col="red")
abline(h=-0.58,col="red")
abline(h=0,col="red")
abline(h=2,col="red")

diffSpikes = round(data.frame(expected = aggregate(as.numeric(results$diff),by=list(results$log2.Mix.1.Mix.2.),median)$Group.1,median = aggregate(as.numeric(results$diff),by=list(results$log2.Mix.1.Mix.2.),median)$x,medianR = aggregate(as.numeric(reduced$diff),by=list(reduced$log2.Mix.1.Mix.2.),median)$x,p01 = aggregate(as.numeric(results$pvalue),by=list(results$log2.Mix.1.Mix.2.),function(a) sum(a<0.01)/length(a))$x,p01R = aggregate(as.numeric(reduced$pvalue),by=list(reduced$log2.Mix.1.Mix.2.),function(a) sum(a<0.01)/length(a))$x,p05 = aggregate(as.numeric(results$pvalue),by=list(results$log2.Mix.1.Mix.2.),function(a) sum(a<0.05)/length(a))$x,p05R = aggregate(as.numeric(reduced$pvalue),by=list(reduced$log2.Mix.1.Mix.2.),function(a) sum(a<0.05)/length(a))$x),2)

colnames(diffSpikes) = c("expected log 2 difference","median difference","median difference (spikes > 0.5)","pct of spikes with sig diff (p<0.01)","pct of spikes with sig diff (p<0.01 - spikes > 0.5)","pct of spikes with sig diff (p<0.05)","pct of spikes with sig diff (p<0.05 - spikes > 0.5)")

```
Red lines represent the expected log 2 fold differences.  Only spikes that were included in a concentration greater than 0.5 in both samples were included in figure (66 out of 92 spikes).

```{r, results='asis',echo=FALSE,eval=FALSE}
kable(diffSpikes,align=rep("c",ncol(diffSpikes)),row.names=FALSE)
```




12.  Strain-Specific Transcriptome Reconstruction (Ensembl-Guided)
--------------------------

```
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/reconSHR.liver.sh
qsub -q smp /home/data/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/reconBNLx.liver.sh
```

13.  Create BigWig Files
-------------------
```
qsub -q smp /home/saba/BNLx.SHR.Liver.totalRNA.UCD/programs/testBigWig.sh
```

